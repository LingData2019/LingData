---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

### Seminar 2

File `sizes.txt` contains a list of sizes (in bytes) of all Russian Wikipedia articles on artists (retrieved 18.01.2019). We can read it into vector with `scan` function.

```{r}
sizes <- scan("http://math-info.hse.ru/f/2018-19/ling-data/artists-sizes.txt")
```

Let's look at some descriptive statistics:

```{r}
summary(sizes)
```

We see that there's some rather small articles (less than 1000 bytes) and also some large articles (about half a megabyte!). Let's try to visualize it using histogram:

```{r}
hist(sizes)
```

This gives us little clues about the distribution. Let's increase number of bins.

```{r}
hist(sizes, breaks = 100)
```

Again, the most of the picture is useless as it corresponds to very small number of very large values. What can we do?

One of the possible options is to filter our data: keep only not-so-large articles, e.g. less than 50000 bytes (50K).

```{r}
filtered_sizes <- sizes[sizes < 50000]
summary(filtered_sizes)
```

How many elements we removed?

```{r}
length(sizes) - length(filtered_sizes)
```

```{r}
hist(filtered_sizes, breaks = 100)
```

This picture is nice!

Now let us make some samples and plot their histograms.

```{r}
smpl <- sample(filtered_sizes, size = 10, replace = T)
hist(smpl)
```
```{r}
smpl <- sample(filtered_sizes, size = 10, replace = T)
hist(smpl)
```

```{r}
smpl <- sample(filtered_sizes, size = 10, replace = T)
hist(smpl)
```

```{r}
smpl <- sample(filtered_sizes, size = 10, replace = T)
hist(smpl)
```


We get different histogram every time, and they are not so much close to the histogram of the initial vector. Let us increase size of a sample.

```{r}
smpl <- sample(filtered_sizes, size = 100, replace = T)
hist(smpl)
```
```{r}
smpl <- sample(filtered_sizes, size = 100, replace = T)
hist(smpl)
```
```{r}
smpl <- sample(filtered_sizes, size = 500, replace = T)
hist(smpl, breaks = 30)
```

```{r}
length(filtered_sizes)
```

