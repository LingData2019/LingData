---
title: "Lab 13. PCA and MCA"
output: pdf_document
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

```{r}
library(tidyverse)
library(ggfortify)
```

### 1 Gospels' frequency word lists 

The gospels of Matthew, Mark, and Luke are referred to as the Synoptic Gospels and stand in contrast to John, whose content is comparatively distinct. This dataset (https://tinyurl.com/y8tcf3uw) contains frequency of selected words (without stopwords, without pronouns and without frequent word "Jesus") as attested in four gospels of the New Testament.

For some visualisations you will need assign row names to the dataframe:

```{r}
gospels <- read.csv("https://tinyurl.com/y8tcf3uw")
row.names(gospels) <- gospels$word
```

#### 1.1 Apply PCA to four continuous variables. What is the cumulative proportion of explained variance for the first and second component?

```{r}
PCA <- prcomp(gospels[,2:5], center = TRUE, scale. = TRUE)
summary(PCA)
```

#### 1.2 Use the `autoplot()` function of the library ggfortify for creating plot like this. 
See more examples here: https://cran.r-project.org/web/packages/ggfortify/vignettes/plot_pca.html

```{r}
autoplot(PCA,
         shape = FALSE,
         loadings = TRUE,
         label = TRUE,
         loadings.label = TRUE)+
  theme_bw()
```

#### 1.3 Predict the coordinates for the word "Jesus", which have the following frequencies: John = 0.05, Luke = 0.01, Mark = 0.02, Matthew = 0.02.

```{r}
predict(PCA, data.frame(John = 0.05, Luke = 0.01, Mark = 0.02, Matthew = 0.02))
```


### 2. Register variation in the British National Corpus

Dataset and discription from Natalia Levshina’s package Rling. 

This is a data set with relative frequencies (proportions) of different word classes in 69 subcorpora of the British National Corpus (the BYU-BNC version).
    Reg — a factor that describes the metaregister with levels Acad, Fiction, Misc, News, NonacProse and Spok
    Ncomm — a numeric vector with relative frequencies of common nouns.
    Nprop — a numeric vector with relative frequencies of proper nouns.
    Vpres — a numeric vector with relative frequencies of verbs in the present tense form, 3rd person singular.
    Vpast — a numeric vector with relative frequencies of verbs in the past tense form.
    P1 — a numeric vector with relative frequencies of the first-person pronouns.
    P2 — a numeric vector with relative frequencies of the second-person pronouns.
    Adj — a numeric vector with relative frequencies of adjectives.
    ConjCoord — a numeric vector with relative frequencies of coordinating conjunctions.
    ConjSub — a numeric vectorwith relative frequencies of subordinating conjunctions.
    Interject — a numeric vector with relative frequencies of interjections.
    Num — a numeric vector with relative frequencies of numerals.

2.1 Apply PCA to all variables. What is the cumulative proportion of explained variance for the first, second and third components?

2.2 Extract the coordinates from the pca object (pca$x), merge with the dataset itself, and create a visualization using the first two components and creating confidence ellipses for each metaregister.

```{r}
reg_bnc <- read.csv("https://goo.gl/19QywL")
pca <- prcomp(reg_bnc[,-1], center = TRUE, scale. = TRUE)
summary(pca)
autoplot(pca,
         shape = FALSE,
         loadings = TRUE,
         label = TRUE,
         loadings.label = TRUE)+
  theme_bw()
reg_bnc <- cbind(reg_bnc, pca$x)

reg_bnc %>% 
  ggplot(aes(PC1, PC2, color = Reg))+
  geom_point()+
  stat_ellipse()+
  theme_bw()
```
